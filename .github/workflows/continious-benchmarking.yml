name: UnitsNet Benchmarks (auto)
on:  
  push:    
    branches: [master]    
    paths:
      - "UnitsNet/*"
      - "UnitsNet.Benchmark/*"
      - ".github/workflows/**"
      - ".github/actions/**"
      

env: 
  EXECUTION_OPTIONS: --disableLogFile --job Short  # see https://benchmarkdotnet.org/articles/guides/console-args.html
  BENCHMARK_PAGES_BRANCH: gh-pages
  BENCHMARK_DATA_FOLDER: benchmarks
  STABLE_BASELINES: "UnitsNet.Benchmark.Baseline" # TODO could use something like *Perf_Double* or System.MathBenchmarks.Double* from dotnet/performance
jobs:  

  scenarios:
    runs-on: ubuntu-latest
    outputs:
      json: ${{ steps.load-matrix.outputs.json }}
    steps:
      - uses: actions/checkout@v2
      - id: load-matrix
        run: |
          SCENARIOS=$(echo $(cat .github/workflows/benchmark-scenarios.json))
          echo "::set-output name=json::$SCENARIOS"
                   
           
  benchmark:
    needs: [ scenarios ]
    #if: github.repository_owner == 'angularsen' # (by default) the workflow doesn't need to run in a fork
    runs-on: windows-latest # required by the older frameworks
    strategy: 
      matrix: 
        scenario: ${{ fromJson(needs.scenarios.outputs.json) }}
    steps:
      - run: echo "Starting benchmarks for ${{ matrix.scenario.benchmark }} (tracked = ${{ matrix.scenario.tracked }}) running on ${{ matrix.scenario.runtime }} (${{ matrix.scenario.dotnet }})"
      
      - run: echo "Benchmark options ${{ matrix.scenario.benchmark-options }}"
      
      - name: "Baseline comparison ${{ matrix.scenario.tracked }}"
        if: matrix.scenario.scaled
        run: echo "Baseline options ${{ matrix.scenario.baseline-options }}"  
              
      # checkout the current branch
      - uses: actions/checkout@v2.3.1
        with:
          path: UnitsNet
           
      # checkout the ResultRescaler
      - name: Checkout the ResultRescaler
        if: matrix.scenario.scaled
        uses: actions/checkout@v2
        with:
          repository: lipchev/performance
          path: performance
          
      # checkout the baseline branch
      - name: Checkout previous results 
        if: matrix.scenario.scaled
        uses: actions/checkout@v2
        with:
          ref: ${{ env.BENCHMARK_PAGES_BRANCH }}
          path: gh-pages
            
      - uses: actions/setup-dotnet@v1
        if: matrix.scenario.dotnet == ''
        with: 
          dotnet-version: 2.1.x # ${{ matrix.scenario.dotnet }}
      
      - uses: actions/setup-dotnet@v1
        if: matrix.scenario.dotnet == ''
        with: 
          dotnet-version: 3.1.x
          
      - uses: actions/setup-dotnet@v1
        if: matrix.scenario.dotnet == ''
        with: 
          dotnet-version: 5.0.x
      
      # executing the benchmark for the current framework(s)
      - name: Benchmark scenario execution (Micro)
        env:
          PERFLAB_TARGET_FRAMEWORKS: ${{ matrix.scenario.framework }}
        if: contains(matrix.scenario.Benchmark, 'Micro')
        run: .\UnitsNet\UnitsNet.Benchmark\Scripts\run-micro-benchmarks.bat ${{ matrix.scenario.runtime }} -f ${{ matrix.scenario.framework }} ${{ matrix.scenario.benchmark-options }} ${{ env.EXECUTION_OPTIONS }}
          
      - name: Benchmark execution (Gradient) 
        env:
          PERFLAB_TARGET_FRAMEWORKS: ${{ matrix.scenario.framework }}
        if: contains(matrix.scenario.Benchmark, 'Gradient')
        run: .\UnitsNet\UnitsNet.Benchmark\Scripts\run-gradient-benchmarks.bat ${{ matrix.scenario.runtime }} -f ${{ matrix.scenario.framework }} ${{ matrix.scenario.benchmark-options }} ${{ env.EXECUTION_OPTIONS }}
                
      - name: Benchmark scenario execution (Baseline)
        env:
          PERFLAB_TARGET_FRAMEWORKS: ${{ matrix.scenario.framework }}
        if: matrix.scenario.scaled
        run: .\UnitsNet\UnitsNet.Benchmark\Scripts\run-stable-baseline-benchmarks.bat ${{ matrix.scenario.runtime }} -f ${{ matrix.scenario.framework }} ${{ matrix.scenario.baseline-options }} ${{ env.EXECUTION_OPTIONS }}
                
      - name: Stable baseline comparison
        if: matrix.scenario.scaled
        env:
          PERFLAB_TARGET_FRAMEWORKS: ${{ matrix.scenario.framework }}
        run: |
          if (Test-Path .\gh-pages\${{ env.BENCHMARK_DATA_FOLDER }}\${{ matrix.scenario.runtime }}\Baseline ) {
            echo "Running the ResultRescaler using the original baseline"
            Get-ChildItem -Path .\gh-pages\${{ env.BENCHMARK_DATA_FOLDER }}\${{ matrix.scenario.runtime }}\Baseline *-report-scale.json -Recurse |
            % {Copy-Item -Force -Path $_.FullName -Destination $_.FullName.Replace("-report-scale.json", "-report-full.json") }
            dotnet run --project 'performance/src/tools/ResultRescaler' -c Release -f ${{ matrix.scenario.framework }} `
            --base gh-pages\${{ env.BENCHMARK_DATA_FOLDER }}\${{ matrix.scenario.runtime }}\Baseline `
            --diff UnitsNet\Artifacts\Benchmark `
            --stable ${{ env.STABLE_BASELINES }} `
            --output UnitsNet\Artifacts\Benchmark          
          }else{
            echo "No previous baseline found (using current results)"
            Get-ChildItem -Path .\UnitsNet\Artifacts\Benchmark\ *-report-full.json -Recurse | % {Copy-Item -Path $_.FullName -Destination $_.FullName.Replace("-report-full.json", "-report-rescaled.json") }
            Get-ChildItem -Path .\UnitsNet\Artifacts\Benchmark\*\Baseline *-report-full.json -Recurse | % {Copy-Item -Path $_.FullName -Destination $_.FullName.Replace("-report-full.json", "-report-scale.json") }
          }      
                
      # saving the current artifact (downloadable until the expiration date of this action)        
      - name: Store micro benchmark artifact
        if: contains(matrix.scenario.Benchmark, 'Micro')
        uses: actions/upload-artifact@v2
        with:
          name: Micro Benchmarks (${{ matrix.scenario.runtime }})
          path: UnitsNet\Artifacts\Benchmark\Micro
          
      - name: Store gradient benchmark artifact
        if: contains(matrix.scenario.Benchmark, 'Gradient')
        uses: actions/upload-artifact@v2
        with:
          name: UnitsNet Gradient Benchmarks (${{ matrix.scenario.runtime }})
          path: UnitsNet\Artifacts\Benchmark\Gradient
          
      - name: Store baseline benchmark artifact
        if: matrix.scenario.scaled
        uses: actions/upload-artifact@v2
        with:
          name: UnitsNet Baseline Benchmarks (${{ matrix.scenario.runtime }})
          path: UnitsNet\Artifacts\Benchmark\Baseline
          
  publish-results:
    needs: [benchmark, scenarios]
    runs-on: ubuntu-latest
    outputs:
      reports: ${{ steps.path.update-reports.reports }} 
    strategy:
      max-parallel: 1 # cannot commit on the same branch in parallel
      matrix: 
        scenario: ${{ fromJson(needs.scenarios.outputs.json) }}
    steps:                 
      # The benchmarks reporistory (e.g. gh-pages) is checked out 
      - name: Benchmark reporistory checkout ️
        uses: actions/checkout@v2
        with:
          ref: ${{ env.BENCHMARK_PAGES_BRANCH }}
      
      # The benchmark results are downloaded into the corresponding 'scenario' folder.
      - name: Download micro benchmark artifact
        if: contains(matrix.scenario.Benchmark, 'Micro')
        uses: actions/download-artifact@v2
        with:
          name: UnitsNet Micro Benchmarks (${{ matrix.scenario.runtime }})
          path: .${{ matrix.scenario.runtime }}/Micro        
          
      - name: Download gradient benchmark artifact
        if: contains(matrix.scenario.Benchmark, 'Gradient')
        uses: actions/download-artifact@v2
        with:
          name: UnitsNet Gradient Benchmarks (${{ matrix.scenario.runtime }})
          path: .${{ matrix.scenario.runtime }}/Gradient  
          
      - name: Download baseline benchmark artifact
        if: matrix.scenario.scaled
        uses: actions/download-artifact@v2
        with:
          name: UnitsNet Baseline Benchmarks (${{ matrix.scenario.runtime }})
          path: .${{ matrix.scenario.runtime }}/Baseline  
          
      # Copy all of the results to the target framework folder and output the (json) list of updated json files
      - name: Update benchmark reports
        id: update-reports
        working-directory: ${{ env.BENCHMARK_DATA_FOLDER }}
        run: |
          $Reports = Get-ChildItem .${{ matrix.scenario.runtime }} | 
          Move-Item -Destination ${{ matrix.scenario.runtime }} -Force -PassThru | 
          Get-ChildItem -Recurse -Filter *.json | Resolve-Path -Relative | ConvertTo-Json -Compress
          rm .${{ matrix.scenario.runtime }}
          echo "::set-output name=reports::$Reports"
        shell: pwsh
      
      # Push the modifications to the benchmarks branch
      - name: Git Auto Commit
        uses: stefanzweifel/git-auto-commit-action@v4.11.0
        with:
          commit_message: Automatic benchmark generation for ${{ github.sha }} (${{ matrix.scenario.runtime }})  
  
  get-reports:
    if: false # break glass in case of emergency
    runs-on: ubuntu-latest
    outputs:
      reports: ${{ steps.path.outputs.reports }}        
    steps:
      - name: Initializing git folder ️
        uses: actions/checkout@v2.3.1
        with:
          ref: ${{ env.BENCHMARK_PAGES_BRANCH }}
          
      - name: Result path configuration
        id: path
        working-directory: ${{ env.BENCHMARK_DATA_FOLDER }}
        run: |
          $Reports = Get-ChildItem -Filter *report*.json -Recurse | Resolve-Path -Relative | ConvertTo-Json -Compress
          echo "::set-output name=reports::$Reports"
        shell: pwsh 
        
      - name: Result
        run: echo ${{ steps.path.outputs.reports }}
        
  update-history:
    #needs: [ get-reports ]
    needs: [publish-results]
    runs-on: ubuntu-latest
    continue-on-error: false
    strategy:
      max-parallel: 1 # we cannot commit on the same branch in parallel (multiple points added on retry- can we 'force' this?)
      matrix: 
        report-path: ${{ fromJson(needs.publish-results.outputs.reports) }}
    steps:        
      - name: Initializing git folder ️
        uses: actions/checkout@v2.3.1
        
      # The latest results are downloaded from the gh-pages url into the 'Artifacts/Benchmark' folder.  
      - name: Fetch report
        id: download
        uses: carlosperate/download-file-action@v1.0.3
        with:
          file-url: ${{ github.actor }}.github.io/${{ github.event.repository.name }}/${{ env.BENCHMARK_DATA_FOLDER }}/${{ matrix.report-path }}
          location: Artifacts/Benchmark
              
      - name: History path selection
        id: history
        run: |
          $Name = (Get-Item ${{ steps.download.outputs.file-path }}).BaseName
          $Path = if ($Name.Contains('rescaled')) {
            (Split-Path ${{ matrix.report-path }} | Split-Path).replace('./', '') + '/history/report-rescaled'
          }
          else{
            (Split-Path ${{ matrix.report-path }} | Split-Path).replace('./', '') + '/history/report-full'
          }
          echo "::set-output name=target-name::$Name"
          echo "::set-output name=target-path::$Path"
        shell: pwsh
          
      # appending to the running benchmark data on the benchmark-pages branch
      - name: Updating benchmark charts
        if: contains(steps.history.outputs.target-path, 'history')  
        uses: starburst997/github-action-benchmark@v1.8.7
        with:
          name: ${{ steps.history.outputs.target-name }}
          tool: 'benchmarkdotnet'
          output-file-path: ${{ steps.download.outputs.file-path }}
          gh-pages-branch: ${{ env.BENCHMARK_PAGES_BRANCH }}
          benchmark-data-dir-path: ${{ env.BENCHMARK_DATA_FOLDER }}/${{ steps.history.outputs.target-path }}
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          # Show alert with commit comment on detecting possible performance regression
          alert-threshold: '100%'
          comment-always: false
          comment-on-alert: ${{ contains(steps.history.outputs.target-path, 'rescaled') }}
          fail-on-alert: false
          alert-comment-cc-users: '@lipchev'
        
      - name: Result
        run: echo http://${{ github.actor }}.github.io/${{ github.event.repository.name }}/${{ env.BENCHMARK_DATA_FOLDER }}/${{ steps.history.outputs.target-path }}/
     
  
     
